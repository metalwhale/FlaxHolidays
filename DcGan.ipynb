{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DcGan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- [Anime-Face-Dataset](https://github.com/bchao1/Anime-Face-Dataset)\n",
        "- [Anime-Face-GAN](https://github.com/yashyenugu/Anime-Face-GAN)\n",
        "- [jax-dcgan](https://github.com/bilal2vec/jax-dcgan)"
      ],
      "metadata": {
        "id": "XoproDGI3WET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "zaDi1TRm3rOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flax"
      ],
      "metadata": {
        "id": "BoK6zBE33sfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "ry5GPpoo3i6K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dz7Oesl9dnK"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/uc?id=1HG7YnakUkjaxtNMclbl2t5sJwGLcHYsI # Download `data.tgz` file\n",
        "!tar -xzf data.tgz # Extract\n",
        "!mv cropped data # Rename extracted folder\n",
        "!rm data.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imghdr\n",
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "class Anime:\n",
        "    def __init__(self, image_path: str):\n",
        "        self.image_path = image_path\n",
        "\n",
        "def _walk_children(path: str, full_path: bool, walk_dirs: bool) -> List[str]:\n",
        "    return sorted([\n",
        "        os.path.join(path, name) if full_path else name\n",
        "        for name in next(os.walk(path))[1 if walk_dirs else 2]\n",
        "    ])\n",
        "\n",
        "def collect_data() -> Tuple[Tuple[List[Anime], ...], List[str]]:\n",
        "    DATA_PATH = \"data\"\n",
        "    data_list = [Anime(image_path) for image_path in _walk_children(\"data\", True, False) if imghdr.what(image_path) is not None]\n",
        "    return data_list\n",
        "\n",
        "def make_slices(data_list: List[Anime]) -> Dict[str, List]:\n",
        "    slices = {}\n",
        "    slices[\"image\"] = [anime.image_path for anime in data_list]\n",
        "    return slices"
      ],
      "metadata": {
        "id": "dH-GZwCWxgg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Reader:\n",
        "    def __init__(self, image_size: Tuple[int, int]):\n",
        "        self.image_size = image_size # (height, width)\n",
        "\n",
        "    def read(self, sources: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "        return self._read_image(sources[\"image\"])\n",
        "\n",
        "    def _read_image(self, source: tf.Tensor) -> tf.Tensor:\n",
        "        image = tf.io.read_file(source)\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "        image = tf.image.resize(image, self.image_size)\n",
        "        image /= 255\n",
        "        return image\n",
        "\n",
        "def generate_dataset(slices: Dict[str, List], reader: Reader, batch_size: int, shuffle: bool) -> tf.data.Dataset:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(slices)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=max(len(data) for data in slices.values()))\n",
        "    dataset = dataset.map(\n",
        "        reader.read,\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    ).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "FhkrW4SpzQ-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "tJ_JAcRN1Zf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as fl\n",
        "\n",
        "class Discriminator(fl.Module):\n",
        "    @fl.compact\n",
        "    def __call__(self, x):\n",
        "        x = fl.Conv(32, (3, 3), strides=2)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.Conv(64, (3, 3), strides=2)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.Conv(128, (3, 3), strides=2)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.Conv(256, (3, 3), strides=2)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.Conv(512, (3, 3), strides=2)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = x.reshape((x.shape[0], -1))\n",
        "        x = fl.Dense(1)(x)\n",
        "        return x\n",
        "\n",
        "class Generator(fl.Module):\n",
        "    @fl.compact\n",
        "    def __call__(self, x):\n",
        "        x = fl.Dense(2 * 2 * 512)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = x.reshape((x.shape[0], 2, 2, 512)) # (2, 2, 512)\n",
        "        x = fl.ConvTranspose(256, (3, 3), strides=(2, 2))(x) # (4, 4, 256)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.ConvTranspose(128, (3, 3), strides=(2, 2))(x) # (8, 8, 128)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.ConvTranspose(64, (3, 3), strides=(2, 2))(x) # (16, 16, 64)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.ConvTranspose(32, (3, 3), strides=(2, 2))(x) # (32, 32, 32)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.ConvTranspose(3, (3, 3), strides=(2, 2))(x) # (64, 64, 3)\n",
        "        x = fl.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "PDM7caEL1ZHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax.training import train_state as ft\n",
        "\n",
        "LATENT_SIZE = 128\n",
        "\n",
        "def _bce_logit(x: jnp.DeviceArray, y: np.ndarray) -> jnp.DeviceArray:\n",
        "    # Binary Cross Entropy with Logits\n",
        "    x = x.reshape(x.shape[0])\n",
        "    return jnp.mean(x - y * x + jnp.log(1 + jnp.exp(-x)))\n",
        "\n",
        "# @jax.jit\n",
        "def _disc_train_batch(disc_state: ft.TrainState, gen_state: ft.TrainState, real: np.ndarray, noise: np.ndarray) -> Tuple[ft.TrainState, jnp.DeviceArray]:\n",
        "    def _disc_loss(params):\n",
        "        fake = gen_state.apply_fn({\"params\": gen_state.params}, noise)\n",
        "        pred = disc_state.apply_fn({\"params\": params}, np.concatenate([real, fake]))\n",
        "        loss = _bce_logit(pred, np.concatenate([np.ones(real.shape[0]), np.zeros(fake.shape[0])]))\n",
        "        return loss\n",
        "    loss, grads = jax.value_and_grad(_disc_loss)(disc_state.params)\n",
        "    disc_state = disc_state.apply_gradients(grads=grads)\n",
        "    return disc_state, loss\n",
        "\n",
        "# @jax.jit\n",
        "def _gen_train_batch(disc_state: ft.TrainState, gen_state: ft.TrainState, noise: np.ndarray) -> Tuple[ft.TrainState, jnp.DeviceArray]:\n",
        "    def _gen_loss(params):\n",
        "        fake = gen_state.apply_fn({\"params\": params}, noise)\n",
        "        pred = disc_state.apply_fn({\"params\": disc_state.params}, fake)\n",
        "        loss = _bce_logit(pred, np.ones(pred.shape[0]))\n",
        "        return loss\n",
        "    loss, grads = jax.value_and_grad(_gen_loss)(gen_state.params)\n",
        "    gen_state = gen_state.apply_gradients(grads=grads)\n",
        "    return gen_state, loss\n",
        "\n",
        "def train_epoch(\n",
        "        disc_state: ft.TrainState, gen_state: ft.TrainState, dataset\n",
        "    ) -> Tuple[ft.TrainState, ft.TrainState, np.float32, np.float32]:\n",
        "    disc_losses = []\n",
        "    gen_losses = []\n",
        "    batchs_num = 0\n",
        "    for real in dataset:\n",
        "        noise = np.random.normal(size=(real.shape[0], LATENT_SIZE))\n",
        "        disc_state, disc_loss = _disc_train_batch(disc_state, gen_state, real, noise)\n",
        "        disc_losses.append(disc_loss)\n",
        "        batchs_num += 1\n",
        "    for _ in range(batchs_num):\n",
        "        noise = np.random.normal(size=(real.shape[0], LATENT_SIZE))\n",
        "        gen_state, gen_loss = _gen_train_batch(disc_state, gen_state, noise)\n",
        "        gen_losses.append(gen_loss)\n",
        "    disc_epoch_loss = np.mean(jax.device_get(disc_losses))\n",
        "    gen_epoch_loss = np.mean(jax.device_get(gen_losses))\n",
        "    return disc_state, gen_state, disc_epoch_loss, gen_epoch_loss"
      ],
      "metadata": {
        "id": "mgkcHKtRGAje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sigmoid`:\n",
        "$$\n",
        "  p(x)=\\frac{1}{1+e^{-x}}\n",
        "$$\n",
        "`bce`:\n",
        "$$\n",
        "  l(p, y)=-(y\\log(p)+(1-y)\\log(1-p))\n",
        "$$\n",
        "`bce_logit`:\n",
        "$$\n",
        "  l(x, y)=-(y\\log(\\frac{1}{1+e^{-x}})+(1-y)\\log(1-\\frac{1}{1+e^{-x}}))=x-yx+\\log(1+e^{-x})\n",
        "$$"
      ],
      "metadata": {
        "id": "pov9i1-Kfxfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "vR8XF2v10G1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = (64, 64)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "\n",
        "# Dataset\n",
        "data_list = collect_data()\n",
        "data_slices = make_slices(data_list)\n",
        "dataset = tfds.as_numpy(generate_dataset(data_slices, Reader(IMAGE_SIZE), BATCH_SIZE, True))\n",
        "\n",
        "# Model and state\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rng, disc_rng, gen_rng = jax.random.split(rng, 3)\n",
        "disc_model = Discriminator()\n",
        "gen_model = Generator()\n",
        "disc_state = ft.TrainState.create(\n",
        "    apply_fn=disc_model.apply,\n",
        "    params=disc_model.init(disc_rng, jnp.zeros([1, *IMAGE_SIZE, 3]))[\"params\"],\n",
        "    tx=optax.adam(0.001)\n",
        ")\n",
        "gen_state = ft.TrainState.create(\n",
        "    apply_fn=gen_model.apply,\n",
        "    params=gen_model.init(gen_rng, jnp.zeros([1, LATENT_SIZE]))[\"params\"],\n",
        "    tx=optax.adam(0.001)\n",
        ")"
      ],
      "metadata": {
        "id": "U-I9ZsW-0JQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _generate():\n",
        "    fake = gen_state.apply_fn({\"params\": gen_state.params}, np.random.normal(size=(12, LATENT_SIZE)))\n",
        "    plt.figure(figsize=(24, 2))\n",
        "    plt.imshow(np.concatenate(fake, axis=1))\n",
        "    plt.show()\n",
        "\n",
        "# Training\n",
        "_generate()\n",
        "for epoch in range(EPOCHS):\n",
        "    disc_state, gen_state, disc_loss, gen_loss = train_epoch(disc_state, gen_state, dataset)\n",
        "    print(f\"Epoch {epoch}, disc_loss: {disc_loss:.4f}, gen_loss: {gen_loss:.4f}\")\n",
        "    _generate()"
      ],
      "metadata": {
        "id": "1_F86dMdpSMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}