{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- [Annotated MNIST](https://flax.readthedocs.io/en/latest/notebooks/annotated_mnist.html)\n",
        "- [Training a Simple Neural Network, with tensorflow/datasets Data Loading](https://jax.readthedocs.io/en/latest/notebooks/neural_network_with_tfds_data.html)"
      ],
      "metadata": {
        "id": "1BkkiNhqVxsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "v4I5Ea4B005e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "orKpIvOs0v7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b95b488-226f-432f-c25e-f80b415c5c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flax\n",
            "  Downloading flax-0.3.6-py3-none-any.whl (207 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 51 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 61 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 81 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 102 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 112 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 122 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 133 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 143 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 153 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 163 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 174 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 184 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 194 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 204 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 207 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.2.21 in /usr/local/lib/python3.7/dist-packages (from flax) (0.2.25)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from flax) (1.19.5)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->flax) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.21->flax) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.2)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax->flax) (0.1.71+cuda111)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib>=0.1.37->optax->flax) (2.0)\n",
            "Installing collected packages: chex, optax, flax\n",
            "Successfully installed chex-0.1.0 flax-0.3.6 optax-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flax"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "42FyJv-o1KMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
        "!curl -o flower_photos.tgz https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
        "!tar -xzf flower_photos.tgz\n",
        "!rm flower_photos.tgz"
      ],
      "metadata": {
        "id": "iWr-FNSBYDFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c54e09-33b3-4743-f39d-92b1ba9589a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  218M  100  218M    0     0   135M      0  0:00:01  0:00:01 --:--:--  134M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from tensorflow.keras import utils as tfku\n",
        "\n",
        "class Flower:\n",
        "    def __init__(self, image_path: str, label: str):\n",
        "        self.image_path = image_path\n",
        "        self.label = label\n",
        "\n",
        "def collect_data() -> Tuple[Tuple[List[\"Flower\"], ...], List[str]]:\n",
        "    def walk_children(path: str, full_path: bool, walk_dirs: bool=True) -> List[str]:\n",
        "        return sorted([\n",
        "            os.path.join(path, name) if full_path else name\n",
        "            for name in next(os.walk(path))[1 if walk_dirs else 2]\n",
        "        ])\n",
        "    DATA_PATH = \"flower_photos\"\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    labels = walk_children(DATA_PATH, False, walk_dirs=True)\n",
        "    for label in labels:\n",
        "        for i, image_path in enumerate(walk_children(os.path.join(DATA_PATH, label), True, walk_dirs=False)):\n",
        "            flower = Flower(image_path, label)\n",
        "            if i % 5 != 0:\n",
        "                train_list.append(flower)\n",
        "            else:\n",
        "                val_list.append(flower)\n",
        "    return (train_list, val_list), labels\n",
        "\n",
        "def make_slices_dict(flowers_list: List[Flower], labels: List[str]) -> Dict[str, List]:\n",
        "    slices = {}\n",
        "    slices[\"image\"] = [flower.image_path for flower in flowers_list]\n",
        "    slices[\"output\"] = tfku.to_categorical([labels.index(flower.label) for flower in flowers_list], num_classes=len(labels))\n",
        "    return slices"
      ],
      "metadata": {
        "id": "rdMk8eKQ1JEf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Reader:\n",
        "    def __init__(self, image_size: Tuple[int, int], augment: bool):\n",
        "        self.image_size = image_size # (height, width)\n",
        "        self.augment = augment\n",
        "\n",
        "    def read_input(self, sources: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "        return self._read_image(sources[\"image\"])\n",
        "\n",
        "    def read_output(self, sources: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "        return sources[\"output\"]\n",
        "\n",
        "    def _read_image(self, source: tf.Tensor) -> tf.Tensor:\n",
        "        image = tf.io.read_file(source)\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "        if self.augment:\n",
        "            image = tf.image.random_brightness(image, 0.5)\n",
        "            image = tf.image.random_contrast(image, 0.2, 0.8)\n",
        "            image = tf.image.random_crop(image, [\n",
        "                tf.random.uniform([], minval=0.8, maxval=1.0) * tf.cast(tf.shape(image)[0], tf.float32),\n",
        "                tf.random.uniform([], minval=0.8, maxval=1.0) * tf.cast(tf.shape(image)[1], tf.float32),\n",
        "                3\n",
        "            ])\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "        image = tf.image.resize(image, self.image_size)\n",
        "        image /= 255\n",
        "        return image\n",
        "\n",
        "def generate_dataset(slices: Dict[str, List], reader: Reader, batch_size: int, shuffle: bool) -> tf.data.Dataset:\n",
        "    def _read_data(sources: Dict[str, tf.Tensor]) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "        input_data = reader.read_input(sources)\n",
        "        output_data = reader.read_output(sources)\n",
        "        return (input_data if len(input_data) > 1 else input_data[0], output_data)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(slices)\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=max(len(data) for data in slices.values()))\n",
        "    dataset = dataset.map(\n",
        "        lambda data: _read_data(data),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    ).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "-UIVPZGmfoeG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "8imK24vpL2rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as fl\n",
        "\n",
        "class Cnn(fl.Module):\n",
        "    labels_num: int\n",
        "\n",
        "    @fl.compact\n",
        "    def __call__(self, x):\n",
        "        x = fl.Conv(32, (3, 3))(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.avg_pool(x, (2, 2), strides=(2, 2))\n",
        "        x = fl.Conv(64, (3, 3))(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.avg_pool(x, (2, 2), strides=(2, 2))\n",
        "        x = fl.Conv(128, (3, 3))(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.avg_pool(x, (2, 2), strides=(2, 2))\n",
        "        x = x.reshape((x.shape[0], -1)) # Flatten\n",
        "        x = fl.Dense(256)(x)\n",
        "        x = fl.relu(x)\n",
        "        x = fl.Dense(self.labels_num)(x)\n",
        "        x = fl.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YdaucQJ6L3_Y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from flax.training import train_state as ft\n",
        "\n",
        "def _calculate_loss(pred: jnp.DeviceArray, truth: np.ndarray) -> jnp.DeviceArray:\n",
        "    # Cross-entropy\n",
        "    return jnp.mean(-jnp.sum(truth * jnp.log(pred), axis=-1))\n",
        "\n",
        "def _calculate_acc(pred: jnp.DeviceArray, truth: np.ndarray) -> jnp.DeviceArray:\n",
        "    return jnp.mean(jnp.argmax(pred, axis=-1) == jnp.argmax(truth, axis=-1))\n",
        "\n",
        "def _compute_epoch_metric(metrics: List[Dict[str, jnp.DeviceArray]]) -> Dict[str, np.float32]:\n",
        "    return {\n",
        "        k: np.mean([m[k] for m in jax.device_get(metrics)])\n",
        "        for k in [\"loss\", \"acc\"]\n",
        "    }\n",
        "\n",
        "def train_epoch(state: ft.TrainState, train_dataset: tf.data.Dataset) -> Tuple[ft.TrainState, Dict[str, np.float32]]:\n",
        "    @jax.jit\n",
        "    def train_batch(state, batch):\n",
        "        image, truth = batch\n",
        "        def loss_fn(params):\n",
        "            pred = state.apply_fn({\"params\": params}, image)\n",
        "            loss = _calculate_loss(pred, truth)\n",
        "            return loss, pred\n",
        "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "        (loss, pred), grads = grad_fn(state.params)\n",
        "        state = state.apply_gradients(grads=grads)\n",
        "        metric = {\n",
        "            \"loss\": loss,\n",
        "            \"acc\": _calculate_acc(pred, truth)\n",
        "        }\n",
        "        return state, metric\n",
        "    batch_metrics = []\n",
        "    for batch in train_dataset:\n",
        "        state, metric = train_batch(state, batch)\n",
        "        batch_metrics.append(metric)\n",
        "    epoch_metric = _compute_epoch_metric(batch_metrics)\n",
        "    return state, epoch_metric\n",
        "\n",
        "def eval_epoch(state: ft.TrainState, val_dataset: tf.data.Dataset) -> Dict[str, np.float32]:\n",
        "    def eval_batch(state, batch):\n",
        "        image, truth = batch\n",
        "        pred = state.apply_fn({\"params\": state.params}, image)\n",
        "        metric = {\n",
        "            \"loss\": _calculate_loss(pred, truth),\n",
        "            \"acc\": _calculate_acc(pred, truth)\n",
        "        }\n",
        "        return metric\n",
        "    batch_metrics = jax.device_get([eval_batch(state, batch) for batch in val_dataset])\n",
        "    epoch_metric = _compute_epoch_metric(batch_metrics)\n",
        "    return epoch_metric"
      ],
      "metadata": {
        "id": "LbHfDStCvVYa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "6Afz___EKRRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "\n",
        "# Dataset\n",
        "(train_list, val_list), labels = collect_data()\n",
        "train_slices = make_slices_dict(train_list, labels)\n",
        "val_slices = make_slices_dict(val_list, labels)\n",
        "train_dataset = tfds.as_numpy(generate_dataset(train_slices, Reader(IMAGE_SIZE, True), BATCH_SIZE, True))\n",
        "val_dataset = tfds.as_numpy(generate_dataset(val_slices, Reader(IMAGE_SIZE, False), BATCH_SIZE, False))\n",
        "\n",
        "# Model and state\n",
        "model = Cnn(labels_num=len(labels))\n",
        "state = ft.TrainState.create(\n",
        "    apply_fn=model.apply,\n",
        "    params=model.init(jax.random.PRNGKey(0), jnp.ones([1, *IMAGE_SIZE, 3]))[\"params\"],\n",
        "    tx=optax.adam(0.001)\n",
        ")\n",
        "\n",
        "# Training\n",
        "for epoch in range(EPOCHS):\n",
        "    state, train_metric = train_epoch(state, train_dataset)\n",
        "    val_metric = eval_epoch(state, val_dataset)\n",
        "    print((\n",
        "        f\"Epoch {epoch}, \"\n",
        "        f\"loss: {train_metric['loss']:.4f}, acc: {train_metric['acc']:.2f}, \"\n",
        "        f\"loss: {val_metric['loss']:.4f}, acc: {val_metric['acc']:.2f}\"\n",
        "    ))"
      ],
      "metadata": {
        "id": "JUblLi2_KnRN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41db8dfe-84a9-460c-a692-64a5c63414fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 1.5488, acc: 0.32, loss: 1.3275, acc: 0.39\n",
            "Epoch 1, loss: 1.3704, acc: 0.39, loss: 1.2021, acc: 0.49\n",
            "Epoch 2, loss: 1.3167, acc: 0.43, loss: 1.2521, acc: 0.47\n",
            "Epoch 3, loss: 1.2637, acc: 0.47, loss: 1.2226, acc: 0.50\n",
            "Epoch 4, loss: 1.2271, acc: 0.49, loss: 1.2293, acc: 0.46\n",
            "Epoch 5, loss: 1.1857, acc: 0.51, loss: 1.2572, acc: 0.52\n",
            "Epoch 6, loss: 1.1659, acc: 0.53, loss: 1.2973, acc: 0.48\n",
            "Epoch 7, loss: 1.1267, acc: 0.55, loss: 1.2715, acc: 0.54\n",
            "Epoch 8, loss: 1.1183, acc: 0.55, loss: 1.1361, acc: 0.58\n",
            "Epoch 9, loss: 1.0664, acc: 0.58, loss: 1.2287, acc: 0.57\n"
          ]
        }
      ]
    }
  ]
}